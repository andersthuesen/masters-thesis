@article{liang2024intergen,
  title={Intergen: Diffusion-based multi-human motion generation under complex interactions},
  author={Liang, Han and Zhang, Wenqian and Li, Wenxuan and Yu, Jingyi and Xu, Lan},
  journal={International Journal of Computer Vision},
  pages={1--21},
  year={2024},
  publisher={Springer}
}

@inproceedings{tevet2023human,
  title={Human Motion Diffusion Model},
  author={Guy Tevet and Sigal Raab and Brian Gordon and Yoni Shafir and Daniel Cohen-or and Amit Haim Bermano},
  booktitle={The Eleventh International Conference on Learning Representations },
  year={2023},
  url={https://openreview.net/forum?id=SJ1kSyO2jwu}
}

@inproceedings{Zhou_2019_CVPR,
  title={On the Continuity of Rotation Representations in Neural Networks},
  author={Zhou, Yi and Barnes, Connelly and Jingwan, Lu and Jimei, Yang and Hao, Li},
  booktitle={The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month={June},
  year={2019}
}

@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}

@inproceedings{pmlrv139nichol21a,
  title = {Improved Denoising Diffusion Probabilistic Models},
  author = {Nichol, Alexander Quinn and Dhariwal, Prafulla},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning},
  pages = {8162--8171},
  year = {2021},
  editor = {Meila, Marina and Zhang, Tong},
  volume = {139},
  series = {Proceedings of Machine Learning Research},
  month = {7},
  publisher = {PMLR},
  pdf = {http://proceedings.mlr.press/v139/nichol21a/nichol21a.pdf},
  url = {https://proceedings.mlr.press/v139/nichol21a.html},
  abstract = {Denoising diffusion probabilistic models (DDPM) are a class of generative models which have recently been shown to produce excellent samples. We show that with a few simple modifications, DDPMs can also achieve competitive log-likelihoods while maintaining high sample quality. Additionally, we find that learning variances of the reverse diffusion process allows sampling with an order of magnitude fewer forward passes with a negligible difference in sample quality, which is important for the practical deployment of these models. We additionally use precision and recall to compare how well DDPMs and GANs cover the target distribution. Finally, we show that the sample quality and likelihood of these models scale smoothly with model capacity and training compute, making them easily scalable. We release our code and pre-trained models at https://github.com/openai/improved-diffusion.}
}

@inproceedings{dharial2021diffusion,
  author = {Dhariwal, Prafulla and Nichol, Alexander},
  booktitle = {Advances in Neural Information Processing Systems},
  editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
  pages = {8780--8794},
  publisher = {Curran Associates, Inc.},
  title = {Diffusion Models Beat GANs on Image Synthesis},
  url = {https://proceedings.neurips.cc/paper_files/paper/2021/file/49ad23d1ec9fa4bd8d77d02681df5cfa-Paper.pdf},
  volume = {34},
  year = {2021}
}


@inproceedings{song2019generative,
  title={Generative Modeling by Estimating Gradients of the Data Distribution},
  author={Song, Yang and Ermon, Stefano},
  booktitle={Advances in Neural Information Processing Systems},
  pages={11895--11907},
  year={2019}
}

@article{weng2021diffusion,
  title = "What are diffusion models?",
  author = {{Weng, Lilian}},
  journal = {{lilianweng.github.io}},
  year = "2021",
  month = "Jul",
  url = "https://lilianweng.github.io/posts/2021-07-11-diffusion-models/"
}

@inproceedings{transformer2017,
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
  booktitle = {Advances in Neural Information Processing Systems},
  editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
  pages = {},
  publisher = {Curran Associates, Inc.},
  title = {Attention is All you Need},
  url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
  volume = {30},
  year = {2017}
}

@inproceedings{seq2seq,
  author={Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V.},
  title={Sequence to Sequence Learning with Neural Networks},
  year={2014},
  publisher={MIT Press},
  address={Cambridge, MA, USA},
  abstract={Deep Neural Networks (DNNs) are powerful models that have achieved excellent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets are available, they cannot be used to map sequences to sequences. In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. Our method uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. Our main result is that on an English to French translation task from the WMT-14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM's BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did not have difficulty on long sentences. For comparison, a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which is close to the previous state of the art. The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the passive voice. Finally, we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM's performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier.},
  booktitle={Proceedings of the 27th International Conference on Neural Information Processing Systems - Volume 2},
  pages={3104--3112},
  numpages={9},
  location={Montreal, Canada},
  series={NIPS'14}
}

@inproceedings{goel2023humans,
  title={Humans in 4{D}: Reconstructing and Tracking Humans with Transformers},
  author={Goel, Shubham and Pavlakos, Georgios and Rajasegaran, Jathushan and Kanazawa*, Angjoo and Malik*, Jitendra},
  booktitle={International Conference on Computer Vision (ICCV)},
  year={2023}
}

@inproceedings{depthanything,
  title={Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data},
  author={Yang, Lihe and Kang, Bingyi and Huang, Zilong and Xu, Xiaogang and Feng, Jiashi and Zhao, Hengshuang},
  booktitle={CVPR},
  year={2024}
}

@inproceedings{SilbermanECCV12,
  author = {Nathan Silberman, Derek Hoiem, Pushmeet Kohli and Rob Fergus},
  title = {Indoor Segmentation and Support Inference from RGBD Images},
  booktitle = {ECCV},
  year = {2012}
}

@inproceedings{BogoSMPLify2016,
  title={Keep it {SMPL}: Automatic Estimation of {3D} Human Pose and Shape from a Single Image},
  author={Bogo, Federica and Kanazawa, Angjoo and Lassner, Christoph and Gehler, Peter and Romero, Javier and Black, Michael J.},
  booktitle={Computer Vision -- ECCV 2016},
  series={Lecture Notes in Computer Science},
  publisher={Springer International Publishing},
  month={10},
  year={2016}
}

@InProceedings{hmrKanazawa17,
  title = {End-to-end Recovery of Human Shape and Pose},
  author = {Angjoo Kanazawa and Michael J. Black and David W. Jacobs and Jitendra Malik},
  booktitle = {Computer Vision and Pattern Recognition (CVPR)},
  year = {2018}
}

@inproceedings{kocabas2019vibe,
  title = {VIBE: Video Inference for Human Body Pose and Shape Estimation},
  author = {Kocabas, Muhammed and Athanasiou, Nikos and Black, Michael J.},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month = {6},
  year = {2020}
}

@Inproceedings{kolotouros2021prohmr,
  title = {Probabilistic Modeling for Human Mesh Recovery},
  author = {Kolotouros, Nikos and Pavlakos, Georgios and Jayaraman, Dinesh and Daniilidis, Kostas},
  booktitle = {ICCV},
  year = {2021}
}

@inproceedings{SMPL-X:2019,
  title = {Expressive Body Capture: 3D Hands, Face, and Body from a Single Image},
  author = {Pavlakos, Georgios and Choutas, Vasileios and Ghorbani, Nima and Bolkart, Timo and Osman, Ahmed A. A. and Tzionas, Dimitrios and Black, Michael J.},
  booktitle = {Proceedings IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)},
  year = {2019}
}