@article{liang2024intergen,
  title={Intergen: Diffusion-based multi-human motion generation under complex interactions},
  author={Liang, Han and Zhang, Wenqian and Li, Wenxuan and Yu, Jingyi and Xu, Lan},
  journal={International Journal of Computer Vision},
  pages={1--21},
  year={2024},
  publisher={Springer}
}

@inproceedings{tevet2023human,
  title={Human Motion Diffusion Model},
  author={Guy Tevet and Sigal Raab and Brian Gordon and Yoni Shafir and Daniel Cohen-or and Amit Haim Bermano},
  booktitle={The Eleventh International Conference on Learning Representations },
  year={2023},
  url={https://openreview.net/forum?id=SJ1kSyO2jwu}
}

@inproceedings{Zhou_2019_CVPR,
  title={On the Continuity of Rotation Representations in Neural Networks},
  author={Zhou, Yi and Barnes, Connelly and Jingwan, Lu and Jimei, Yang and Hao, Li},
  booktitle={The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month={June},
  year={2019}
}

@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}

@inproceedings{pmlrv139nichol21a,
  title = {Improved Denoising Diffusion Probabilistic Models},
  author = {Nichol, Alexander Quinn and Dhariwal, Prafulla},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning},
  pages = {8162--8171},
  year = {2021},
  editor = {Meila, Marina and Zhang, Tong},
  volume = {139},
  series = {Proceedings of Machine Learning Research},
  month = {7},
  publisher = {PMLR},
  pdf = {http://proceedings.mlr.press/v139/nichol21a/nichol21a.pdf},
  url = {https://proceedings.mlr.press/v139/nichol21a.html},
  abstract = {Denoising diffusion probabilistic models (DDPM) are a class of generative models which have recently been shown to produce excellent samples. We show that with a few simple modifications, DDPMs can also achieve competitive log-likelihoods while maintaining high sample quality. Additionally, we find that learning variances of the reverse diffusion process allows sampling with an order of magnitude fewer forward passes with a negligible difference in sample quality, which is important for the practical deployment of these models. We additionally use precision and recall to compare how well DDPMs and GANs cover the target distribution. Finally, we show that the sample quality and likelihood of these models scale smoothly with model capacity and training compute, making them easily scalable. We release our code and pre-trained models at https://github.com/openai/improved-diffusion.}
}

@inproceedings{dharial2021diffusion,
  author = {Dhariwal, Prafulla and Nichol, Alexander},
  booktitle = {Advances in Neural Information Processing Systems},
  editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
  pages = {8780--8794},
  publisher = {Curran Associates, Inc.},
  title = {Diffusion Models Beat GANs on Image Synthesis},
  url = {https://proceedings.neurips.cc/paper_files/paper/2021/file/49ad23d1ec9fa4bd8d77d02681df5cfa-Paper.pdf},
  volume = {34},
  year = {2021}
}


@inproceedings{song2019generative,
  title={Generative Modeling by Estimating Gradients of the Data Distribution},
  author={Song, Yang and Ermon, Stefano},
  booktitle={Advances in Neural Information Processing Systems},
  pages={11895--11907},
  year={2019}
}

@article{weng2021diffusion,
  title = "What are diffusion models?",
  author = {{Weng, Lilian}},
  journal = {{lilianweng.github.io}},
  year = "2021",
  month = "Jul",
  url = "https://lilianweng.github.io/posts/2021-07-11-diffusion-models/"
}

@inproceedings{transformer2017,
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
  booktitle = {Advances in Neural Information Processing Systems},
  editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
  pages = {},
  publisher = {Curran Associates, Inc.},
  title = {Attention is All you Need},
  url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
  volume = {30},
  year = {2017}
}

@inproceedings{seq2seq,
  author={Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V.},
  title={Sequence to Sequence Learning with Neural Networks},
  year={2014},
  publisher={MIT Press},
  address={Cambridge, MA, USA},
  abstract={Deep Neural Networks (DNNs) are powerful models that have achieved excellent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets are available, they cannot be used to map sequences to sequences. In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. Our method uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. Our main result is that on an English to French translation task from the WMT-14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM's BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did not have difficulty on long sentences. For comparison, a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which is close to the previous state of the art. The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the passive voice. Finally, we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM's performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier.},
  booktitle={Proceedings of the 27th International Conference on Neural Information Processing Systems - Volume 2},
  pages={3104--3112},
  numpages={9},
  location={Montreal, Canada},
  series={NIPS'14}
}

@inproceedings{goel2023humans,
  title={Humans in 4{D}: Reconstructing and Tracking Humans with Transformers},
  author={Goel, Shubham and Pavlakos, Georgios and Rajasegaran, Jathushan and Kanazawa*, Angjoo and Malik*, Jitendra},
  booktitle={International Conference on Computer Vision (ICCV)},
  year={2023}
}

@inproceedings{depthanything,
  title={Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data},
  author={Yang, Lihe and Kang, Bingyi and Huang, Zilong and Xu, Xiaogang and Feng, Jiashi and Zhao, Hengshuang},
  booktitle={CVPR},
  year={2024}
}

@inproceedings{SilbermanECCV12,
  author = {Nathan Silberman, Derek Hoiem, Pushmeet Kohli and Rob Fergus},
  title = {Indoor Segmentation and Support Inference from RGBD Images},
  booktitle = {ECCV},
  year = {2012}
}

@inproceedings{BogoSMPLify2016,
  title={Keep it {SMPL}: Automatic Estimation of {3D} Human Pose and Shape from a Single Image},
  author={Bogo, Federica and Kanazawa, Angjoo and Lassner, Christoph and Gehler, Peter and Romero, Javier and Black, Michael J.},
  booktitle={Computer Vision -- ECCV 2016},
  series={Lecture Notes in Computer Science},
  publisher={Springer International Publishing},
  month={10},
  year={2016}
}

@InProceedings{hmrKanazawa17,
  title = {End-to-end Recovery of Human Shape and Pose},
  author = {Angjoo Kanazawa and Michael J. Black and David W. Jacobs and Jitendra Malik},
  booktitle = {Computer Vision and Pattern Recognition (CVPR)},
  year = {2018}
}

@inproceedings{kocabas2019vibe,
  title = {VIBE: Video Inference for Human Body Pose and Shape Estimation},
  author = {Kocabas, Muhammed and Athanasiou, Nikos and Black, Michael J.},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month = {6},
  year = {2020}
}

@Inproceedings{kolotouros2021prohmr,
  title = {Probabilistic Modeling for Human Mesh Recovery},
  author = {Kolotouros, Nikos and Pavlakos, Georgios and Jayaraman, Dinesh and Daniilidis, Kostas},
  booktitle = {ICCV},
  year = {2021}
}

@inproceedings{SMPL-X:2019,
  title = {Expressive Body Capture: 3D Hands, Face, and Body from a Single Image},
  author = {Pavlakos, Georgios and Choutas, Vasileios and Ghorbani, Nima and Bolkart, Timo and Osman, Ahmed A. A. and Tzionas, Dimitrios and Black, Michael J.},
  booktitle = {Proceedings IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)},
  year = {2019}
}

@inproceedings{ho2021classifierfree,
  title={Classifier-Free Diffusion Guidance},
  author={Jonathan Ho and Tim Salimans},
  booktitle={NeurIPS 2021 Workshop on Deep Generative Models and Downstream Applications},
  year={2021},
  url={https://openreview.net/forum?id=qw8AKxfYbI}
}

@article{SMPL:2015,
  title = {{SMPL}: A Skinned Multi-Person Linear Model},
  author = {Loper, Matthew and Mahmood, Naureen and Romero, Javier and Pons-Moll, Gerard and Black, Michael J.},
  journal = {ACM Trans. Graphics (Proc. SIGGRAPH Asia)},
  volume = {34},
  number = {6},
  pages = {248:1--248:16},
  publisher = {ACM},
  address = {New York, NY},
  month = oct,
  year = {2015},
  doi = {10.1145/2816795.2818013},
  month_numeric = {10}
}

@article{MANO:SIGGRAPHASIA:2017,
  title = {Embodied Hands: Modeling and Capturing Hands and Bodies Together},
  author = {Romero, Javier and Tzionas, Dimitrios and Black, Michael J.},
  journal = {ACM Transactions on Graphics, (Proc. SIGGRAPH Asia)},
  volume = {36},
  number = {6},
  series = {245:1--245:17},
  month = nov,
  year = {2017},
  month_numeric = {11}
  }

@inproceedings{yuan2023physdiff,
  title={PhysDiff: Physics-Guided Human Motion Diffusion Model},
  author={Yuan, Ye and Song, Jiaming and Iqbal, Umar and Vahdat, Arash and Kautz, Jan},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  year={2023}
}
   

@inproceedings{wang2022humanise,
  title={HUMANISE: Language-conditioned Human Motion Generation in 3D Scenes},
  author={Wang, Zan and Chen, Yixin and Liu, Tengyu and Zhu, Yixin and Liang, Wei and Huang, Siyuan},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2022}
}

@misc{Hwang_2020,
  title={ElderSim: A Synthetic Data Generation Platform for Human Action Recognition in Eldercare Applications}, 
  author={Hochul Hwang and Cheongjae Jang and Geonwoo Park and Junghyun Cho and Ig-Jae Kim},
  year={2020},
  eprint={2010.14742},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/2010.14742}, 
}

@inproceedings{Goodfellow_2014,
  author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  booktitle = {Advances in Neural Information Processing Systems},
  editor = {Z. Ghahramani and M. Welling and C. Cortes and N. Lawrence and K.Q. Weinberger},
  pages = {},
  publisher = {Curran Associates, Inc.},
  title = {Generative Adversarial Nets},
  url = {https://proceedings.neurips.cc/paper_files/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf},
  volume = {27},
  year = {2014}
}

@inproceedings{Shrivastava_2017,
   title={Learning from Simulated and Unsupervised Images through Adversarial Training},
   url={http://dx.doi.org/10.1109/CVPR.2017.241},
   DOI={10.1109/cvpr.2017.241},
   booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
   publisher={IEEE},
   author={Shrivastava, Ashish and Pfister, Tomas and Tuzel, Oncel and Susskind, Joshua and Wang, Wenda and Webb, Russell},
   year={2017},
   month=jul 
  }


@misc{Tremblay_2018,
  title={Training Deep Networks with Synthetic Data: Bridging the Reality Gap by Domain Randomization}, 
  author={Jonathan Tremblay and Aayush Prakash and David Acuna and Mark Brophy and Varun Jampani and Cem Anil and Thang To and Eric Cameracci and Shaad Boochoon and Stan Birchfield},
  year={2018},
  eprint={1804.06516},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/1804.06516}, 
}

@misc{peng2017synthetic,
  title={Synthetic to Real Adaptation with Generative Correlation Alignment Networks},
  author={Xingchao Peng and Kate Saenko},
  year={2017},
  eprint={1701.05524},
  archivePrefix={arXiv},
  primaryClass={cs.CV}
}

@inproceedings{Zheng_2016,
  title={Improving the Robustness of Deep Neural Networks via Stability Training},
  url={http://dx.doi.org/10.1109/CVPR.2016.485},
  DOI={10.1109/cvpr.2016.485},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  publisher={IEEE},
  author={Zheng, Stephan and Song, Yang and Leung, Thomas and Goodfellow, Ian},
  year={2016},
  month=jun 
}

@inproceedings{Dosovitskiy17,
  title = { {CARLA}: {An} Open Urban Driving Simulator},
  author = {Alexey Dosovitskiy and German Ros and Felipe Codevilla and Antonio Lopez and Vladlen Koltun},
  booktitle = {Proceedings of the 1st Annual Conference on Robot Learning},
  pages = {1--16},
  year = {2017}
}

@misc{hu2023gaia1generativeworldmodel,
  title={GAIA-1: A Generative World Model for Autonomous Driving}, 
  author={Anthony Hu and Lloyd Russell and Hudson Yeo and Zak Murez and George Fedoseev and Alex Kendall and Jamie Shotton and Gianluca Corrado},
  year={2023},
  eprint={2309.17080},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/2309.17080}, 
}

@misc{zhang2020generating3dpeoplescenes,
  title={Generating 3D People in Scenes without People}, 
  author={Yan Zhang and Mohamed Hassan and Heiko Neumann and Michael J. Black and Siyu Tang},
  year={2020},
  eprint={1912.02923},
  archivePrefix={arXiv},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/1912.02923}, 
}

@inproceedings{PSI:2019,
  title = {Generating 3D People in Scenes without People},
  author = {Zhang, Yan and Hassan, Mohamed and Neumann, Heiko and Black, Michael J. and Tang, Siyu},
  booktitle = {Computer Vision and Pattern Recognition (CVPR)},
  month = jun,
  year = {2020},
  url = {https://arxiv.org/abs/1912.02923},
  month_numeric = {6}
}

@conference{AMASS:ICCV:2019,
  title = {{AMASS}: Archive of Motion Capture as Surface Shapes},
  author = {Mahmood, Naureen and Ghorbani, Nima and Troje, Nikolaus F. and Pons-Moll, Gerard and Black, Michael J.},
  booktitle = {International Conference on Computer Vision},
  pages = {5442--5451},
  month = oct,
  year = {2019},
  month_numeric = {10}
}

@Inproceedings{kolotouros2019spin,
  Title          = {Learning to Reconstruct 3D Human Pose and Shape via Model-fitting in the Loop},
  Author         = {Kolotouros, Nikos and Pavlakos, Georgios and Black, Michael J and Daniilidis, Kostas},
  Booktitle      = {ICCV},
  Year           = {2019}
}

@inproceedings{multi-hmr2024,
  title={Multi-HMR: Multi-Person Whole-Body Human Mesh Recovery in a Single Shot},
  author={Baradel*, Fabien and Armando, Matthieu and Galaaoui, Salma and Br{\'e}gier, Romain and Weinzaepfel, Philippe and Rogez, Gr{\'e}gory and Lucas*, Thomas},
  booktitle={ECCV},
  year={2024}
}

@inproceedings{rajasegaran2022tracking,
  title={Tracking People by Predicting 3D Appearance, Location and Pose},
  author={Rajasegaran, Jathushan and Pavlakos, Georgios and Kanazawa, Angjoo and Malik, Jitendra},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2740--2749},
  year={2022}
}

@article{dosovitskiy2020vit,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and  Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  journal={ICLR},
  year={2021}
}

@article{devlin2018bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@proceedings{conformer2020,
  title	= {Conformer: Convolution-augmented Transformer for Speech Recognition},
  editor	= {Anmol Gulati and Chung-Cheng Chiu and James Qin and Jiahui Yu and Niki Parmar and Ruoming Pang and Shibo Wang and Wei Han and Yonghui Wu and Yu Zhang and Zhengdong Zhang},
  year	= {2020}
}

@Article{Jumper2021,
  author="Jumper, John
  and Evans, Richard
  and Pritzel, Alexander
  and Green, Tim
  and Figurnov, Michael
  and Ronneberger, Olaf
  and Tunyasuvunakool, Kathryn
  and Bates, Russ
  and {\v{Z}}{\'i}dek, Augustin
  and Potapenko, Anna
  and Bridgland, Alex
  and Meyer, Clemens
  and Kohl, Simon A. A.
  and Ballard, Andrew J.
  and Cowie, Andrew
  and Romera-Paredes, Bernardino
  and Nikolov, Stanislav
  and Jain, Rishub
  and Adler, Jonas
  and Back, Trevor
  and Petersen, Stig
  and Reiman, David
  and Clancy, Ellen
  and Zielinski, Michal
  and Steinegger, Martin
  and Pacholska, Michalina
  and Berghammer, Tamas
  and Bodenstein, Sebastian
  and Silver, David
  and Vinyals, Oriol
  and Senior, Andrew W.
  and Kavukcuoglu, Koray
  and Kohli, Pushmeet
  and Hassabis, Demis",
  title="Highly accurate protein structure prediction with AlphaFold",
  journal="Nature",
  year="2021",
  month="Aug",
  day="01",
  volume="596",
  number="7873",
  pages="583--589",
  abstract="Proteins are essential to life, and understanding their structure can facilitate a mechanistic understanding of their function. Through an enormous experimental effort1--4, the structures of around 100,000 unique proteins have been determined5, but this represents a small fraction of the billions of known protein sequences6,7. Structural coverage is bottlenecked by the months to years of painstaking effort required to determine a single protein structure. Accurate computational approaches are needed to address this gap and to enable large-scale structural bioinformatics. Predicting the three-dimensional structure that a protein will adopt based solely on its amino acid sequence---the structure prediction component of the `protein folding problem'8---has been an important open research problem for more than 50 years9. Despite recent progress10--14, existing methods fall far short of atomic accuracy, especially when no homologous structure is available. Here we provide the first computational method that can regularly predict protein structures with atomic accuracy even in cases in which no similar structure is known. We validated an entirely redesigned version of our neural network-based model, AlphaFold, in the challenging 14th Critical Assessment of protein Structure Prediction (CASP14)15, demonstrating accuracy competitive with experimental structures in a majority of cases and greatly outperforming other methods. Underpinning the latest version of AlphaFold is a novel machine learning approach that incorporates physical and biological knowledge about protein structure, leveraging multi-sequence alignments, into the design of the deep learning algorithm.",
  issn="1476-4687",
  doi="10.1038/s41586-021-03819-2",
  url="https://doi.org/10.1038/s41586-021-03819-2"
}


@inproceedings{haoyietal-informer-2021,
  author    = {Haoyi Zhou and
               Shanghang Zhang and
               Jieqi Peng and
               Shuai Zhang and
               Jianxin Li and
               Hui Xiong and
               Wancai Zhang},
  title     = {Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting},
  booktitle = {The Thirty-Fifth {AAAI} Conference on Artificial Intelligence, {AAAI} 2021, Virtual Conference},
  volume    = {35},
  number    = {12},
  pages     = {11106--11115},
  publisher = {{AAAI} Press},
  year      = {2021},
}

@misc{touvron2023llama2openfoundation,
  title={Llama 2: Open Foundation and Fine-Tuned Chat Models}, 
  author={Hugo Touvron and Louis Martin and Kevin Stone and Peter Albert and Amjad Almahairi and Yasmine Babaei and Nikolay Bashlykov and Soumya Batra and Prajjwal Bhargava and Shruti Bhosale and Dan Bikel and Lukas Blecher and Cristian Canton Ferrer and Moya Chen and Guillem Cucurull and David Esiobu and Jude Fernandes and Jeremy Fu and Wenyin Fu and Brian Fuller and Cynthia Gao and Vedanuj Goswami and Naman Goyal and Anthony Hartshorn and Saghar Hosseini and Rui Hou and Hakan Inan and Marcin Kardas and Viktor Kerkez and Madian Khabsa and Isabel Kloumann and Artem Korenev and Punit Singh Koura and Marie-Anne Lachaux and Thibaut Lavril and Jenya Lee and Diana Liskovich and Yinghai Lu and Yuning Mao and Xavier Martinet and Todor Mihaylov and Pushkar Mishra and Igor Molybog and Yixin Nie and Andrew Poulton and Jeremy Reizenstein and Rashi Rungta and Kalyan Saladi and Alan Schelten and Ruan Silva and Eric Michael Smith and Ranjan Subramanian and Xiaoqing Ellen Tan and Binh Tang and Ross Taylor and Adina Williams and Jian Xiang Kuan and Puxin Xu and Zheng Yan and Iliyan Zarov and Yuchen Zhang and Angela Fan and Melanie Kambadur and Sharan Narang and Aurelien Rodriguez and Robert Stojnic and Sergey Edunov and Thomas Scialom},
  year={2023},
  eprint={2307.09288},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2307.09288}, 
}

@misc{anil2023palm2technicalreport,
  title={PaLM 2 Technical Report}, 
  author={Rohan Anil and Andrew M. Dai and Orhan Firat and Melvin Johnson and Dmitry Lepikhin and Alexandre Passos and Siamak Shakeri and Emanuel Taropa and Paige Bailey and Zhifeng Chen and Eric Chu and Jonathan H. Clark and Laurent El Shafey and Yanping Huang and Kathy Meier-Hellstern and Gaurav Mishra and Erica Moreira and Mark Omernick and Kevin Robinson and Sebastian Ruder and Yi Tay and Kefan Xiao and Yuanzhong Xu and Yujing Zhang and Gustavo Hernandez Abrego and Junwhan Ahn and Jacob Austin and Paul Barham and Jan Botha and James Bradbury and Siddhartha Brahma and Kevin Brooks and Michele Catasta and Yong Cheng and Colin Cherry and Christopher A. Choquette-Choo and Aakanksha Chowdhery and Clément Crepy and Shachi Dave and Mostafa Dehghani and Sunipa Dev and Jacob Devlin and Mark Díaz and Nan Du and Ethan Dyer and Vlad Feinberg and Fangxiaoyu Feng and Vlad Fienber and Markus Freitag and Xavier Garcia and Sebastian Gehrmann and Lucas Gonzalez and Guy Gur-Ari and Steven Hand and Hadi Hashemi and Le Hou and Joshua Howland and Andrea Hu and Jeffrey Hui and Jeremy Hurwitz and Michael Isard and Abe Ittycheriah and Matthew Jagielski and Wenhao Jia and Kathleen Kenealy and Maxim Krikun and Sneha Kudugunta and Chang Lan and Katherine Lee and Benjamin Lee and Eric Li and Music Li and Wei Li and YaGuang Li and Jian Li and Hyeontaek Lim and Hanzhao Lin and Zhongtao Liu and Frederick Liu and Marcello Maggioni and Aroma Mahendru and Joshua Maynez and Vedant Misra and Maysam Moussalem and Zachary Nado and John Nham and Eric Ni and Andrew Nystrom and Alicia Parrish and Marie Pellat and Martin Polacek and Alex Polozov and Reiner Pope and Siyuan Qiao and Emily Reif and Bryan Richter and Parker Riley and Alex Castro Ros and Aurko Roy and Brennan Saeta and Rajkumar Samuel and Renee Shelby and Ambrose Slone and Daniel Smilkov and David R. So and Daniel Sohn and Simon Tokumine and Dasha Valter and Vijay Vasudevan and Kiran Vodrahalli and Xuezhi Wang and Pidong Wang and Zirui Wang and Tao Wang and John Wieting and Yuhuai Wu and Kelvin Xu and Yunhan Xu and Linting Xue and Pengcheng Yin and Jiahui Yu and Qiao Zhang and Steven Zheng and Ce Zheng and Weikang Zhou and Denny Zhou and Slav Petrov and Yonghui Wu},
  year={2023},
  eprint={2305.10403},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2305.10403}, 
}

@misc{radford_language_2019,
  abstract = {Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspecific datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the CoQA dataset matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underfits WebText. Samples from the model reflect these improvements and contain coherent paragraphs of text. These findings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations.},
  added-at = {2023-01-14T15:28:29.000+0100},
  author = {Radford, Alec and Wu, Jeff and Child, Rewon and Luan, D. and Amodei, Dario and Sutskever, Ilya},
  biburl = {https://www.bibsonomy.org/bibtex/272c31587e067e0041527dabb3a34cdb8/lepsky},
  interhash = {b926ece39c03cdf5499f6540cf63babd},
  intrahash = {72c31587e067e0041527dabb3a34cdb8},
  keywords = {chatgpt kuenstliche_intelligenz},
  timestamp = {2023-01-14T15:33:48.000+0100},
  title = {Language models are unsupervised multitask learners},
  url = {https://www.semanticscholar.org/paper/Language-Models-are-Unsupervised-Multitask-Learners-Radford-Wu/9405cc0d6169988371b2755e573cc28650d14dfe},
  urldate = {2023-01-06},
  year = 2019
}
